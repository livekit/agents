# ğŸ™ï¸ LiveKit Voice Agent â€” Semantic Interruption Layer  
### **NSUT Internship Assignment â€” Final Submission**

This repository contains a fully functional LiveKit AI voice agent extended with a **semantic interruption handling layer** that improves conversation flow by intelligently ignoring filler words, identifying real commands, and ensuring smooth humanâ€“agent interaction without modifying LiveKitâ€™s internal VAD pipeline.

---

# ğŸ“Œ Overview

This project enhances a standard LiveKit real-time voice agent by adding a **semantic interruption handling layer** that significantly improves conversational quality and user experience. The system intelligently distinguishes between *filler utterances* and *real interruption commands* while strictly maintaining LiveKitâ€™s internal VAD pipeline without modification, as required by the NSUT Internship assignment.

### ğŸ” Key Capabilities

- **Filler Suppression While Agent Speaks**  
  Words like *â€œummâ€, â€œhaanâ€, â€œuhhâ€, â€œhmmâ€* are ignored when the agent is speaking to avoid false interruptions.

- **Command-Based Interruption**  
  Commands such as *â€œstopâ€, â€œwaitâ€, â€œhold onâ€, â€œpauseâ€* immediately interrupt the agentâ€™s speech and return control to the user.

- **Filler-as-Speech When Agent Is Silent**  
  If the agent is not speaking, fillers are treated as valid intent, ensuring the agent responds naturally.

- **Confidence-Aware Handling**  
  Low-confidence transcripts from STT are ignored, reducing false triggers caused by background noise.

- **Low-Latency, Real-Time Behaviour**  
  The system enforces user turn completion explicitly, ensuring fast, consistent responses from the LLM.

- **External Middleware Architecture**  
  The semantic interruption logic is built entirely as an external layer without altering LiveKitâ€™s VAD or internal components.

This approach results in a highly stable, natural, and intuitive voice interaction system that meets all technical and behavioural specifications of the assignment.


---

## ğŸš€ What Changed

This submission introduces a fully modular **semantic interruption system** layered on top of a standard LiveKit voice agent. All enhancements are implemented externally without modifying LiveKitâ€™s internal VAD pipeline, fully matching the NSUT Internship requirements.


### ğŸ”¹ 1. New Module: `interrupt_handler/`
| File | Description |
|------|-------------|
| `constants.py` | Lists of filler words, command words, and thresholds |
| `middleware.py` | Core logic to classify transcripts into filler/speech/command |
| `utils.py` | Text normalization, word matching, helper utilities |

### ğŸ”¹ 2. Updated Voice Agent
Located inside the `agent/` directory:

| File | Description |
|------|-------------|
| `entrypoint.py` | Agent setup, STT/LLM/TTS initialization, hook installation |
| `session_manager.py` | Turn management, event handling, interruption handling |
| `state.py` | Tracks agent speaking state |
| `config.py` | Reads `.env` and provides runtime config |

### ğŸ”¹ 3. Updated Model Stack

The system now uses:

- **Deepgram Nova-3** â†’ STT  
- **OpenAI GPT-4.1-mini** â†’ LLM  
- **Cartesia Sonic-2** â†’ TTS  

Together, these provide fast, accurate, and natural real-time voice interaction.


## ğŸ—‚ Project Structure

The project is organized into two main modules:

- **`agent/`** â€” The primary LiveKit voice agent (STT â†’ LLM â†’ TTS)
- **`interrupt_handler/`** â€” Custom semantic interruption middleware

Below is the complete directory layout:

.
â”œâ”€â”€ agent/
â”‚   â”œâ”€â”€ config.py
â”‚   â”œâ”€â”€ entrypoint.py
â”‚   â”œâ”€â”€ session_manager.py
â”‚   â””â”€â”€ state.py
â”‚
â”œâ”€â”€ interrupt_handler/
â”‚   â”œâ”€â”€ constants.py
â”‚   â”œâ”€â”€ middleware.py
â”‚   â””â”€â”€ utils.py
â”‚
â”œâ”€â”€ .env
â”œâ”€â”€ .env.example
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md


## ğŸ”§ What Features Work

This system delivers a fully functional, real-time conversational voice agent with a semantic interruption layer designed to improve the natural flow of interaction.  
All core features required by the internship task are implemented and tested.

### âœ”ï¸ 1. Filler Suppression While Agent Speaks
Fillers such as:
- â€œummâ€
- â€œhaanâ€
- â€œuhhâ€
- â€œhmmâ€
- â€œacchaâ€

are **ignored when the agent is speaking**, preventing unnecessary interruptions.

### âœ”ï¸ 2. Command-Based Interruption
Real interruption commands like:
- â€œstopâ€
- â€œwaitâ€
- â€œhold onâ€
- â€œpauseâ€
- â€œexcuse meâ€

trigger an immediate: session.interrupt()

The agentâ€™s speech stops instantly, handing control back to the user.

### âœ”ï¸ 3. Filler-as-Speech When Agent Is Silent
If the agent is not speaking, the same filler words are treated as **normal speech**, ensuring the LLM still responds naturally.

Example:
> User: â€œuhhâ€¦â€  
â†’ Agent processes and responds.

### âœ”ï¸ 4. Confidence-Aware Transcript Handling
Low-confidence STT outputs (background noise, murmurs, distant voices) are automatically ignored to reduce false triggers.

### âœ”ï¸ 5. Reliable Turn Management
After meaningful user input, the system enforces:session.end_user_turn()

This ensures:
- Faster LLM responses  
- Fewer dropped utterances  
- More consistent interaction loops  

### âœ”ï¸ 6. Full Compatibility with LiveKit Agents v1.3.x
All event handling is updated to use: transcription_completed

instead of deprecated message events.

### âœ”ï¸ 7. VAD Pipeline Remains Untouched
The custom interruption logic is layered **externally**, ensuring:
- No modification to LiveKitâ€™s VAD  
- Assignment compliance  
- Clean, maintainable architecture  

### âœ”ï¸ 8. End-to-End Voice Agent Pipeline
With:
- **Deepgram Nova-3** for STT  
- **OpenAI GPT-4.1-mini** for LLM  
- **Cartesia Sonic-2** for TTS  

the system provides fast, smooth, low-latency real-time voice interactions.

### âœ”ï¸ 9. Modular and Testable Codebase
All interruption logic is isolated in:
interrupt_handler/
constants.py
middleware.py
utils.py

ensuring clarity and easy future extension.

Overall, the system provides a natural, stable, and intelligent conversational experience while strictly meeting all assignment constraints.



## ğŸ§ª Steps to Test

### 1ï¸âƒ£ Clone the Repository
```bash
git clone https://github.com/<your-username>/livekit-interrupt-handler
cd livekit-interrupt-handler
```

### 2ï¸âƒ£ Install Requirements & Prepare Environment

Install Python dependencies:
```bash
pip install -r requirements.txt
```

### Create your environment file:
```bash
cp .env.example .env
```

Fill in your API keys inside .env before running the agent:
LiveKit Cloud Credentials :

LIVEKIT_URL=
LIVEKIT_API_KEY=
LIVEKIT_API_SECRET=

Deepgram (Speech-to-Text) : 

DEEPGRAM_API_KEY=

OpenAI (LLM for GPT-4.1-mini) : 

OPENAI_API_KEY=

Cartesia (Text-to-Speech) :

CARTESIA_API_KEY=