# ğŸ™ï¸ LiveKit Voice Agent â€” Interruption Handler - YASH GUPTA
### **NSUT Internship Assignment â€” Final Submission**

# ğŸ“Œ Overview

This project enhances a standard LiveKit real-time voice agent by adding a **interruption handling layer** that significantly improves conversational quality and user experience. The system intelligently distinguishes between *filler utterances* and *real interruption commands* while strictly maintaining LiveKitâ€™s internal VAD pipeline without modification, as required by the NSUT Internship assignment.

### ğŸ” What Features Works : 

- **Filler Suppression While Agent Speaks**  
  Words like *â€œummâ€, â€œhaanâ€, â€œuhhâ€, â€œhmmâ€* are ignored when the agent is speaking to avoid false interruptions.

- **Command-Based Interruption**  
  Commands such as *â€œstopâ€, â€œwaitâ€, â€œhold onâ€, â€œpauseâ€* immediately interrupt the agentâ€™s speech and return control to the user.

- **Filler-as-Speech When Agent Is Silent**  
  If the agent is not speaking, fillers are treated as valid intent, ensuring the agent responds naturally.

- **Confidence-Aware Handling**  
  Low-confidence transcripts from STT are ignored, reducing false triggers caused by background noise.

- **External Middleware Architecture**  
  The semantic interruption logic is built entirely as an external layer without altering LiveKitâ€™s VAD or internal components.

---

## ğŸš€ What Changed

### ğŸ”¹ 1. New Module: `interrupt_handler/`
| File | Description |
|------|-------------|
| `constants.py` | Lists of filler words, command words, and ASR thresholds |
| `middleware.py` | Core logic to classify transcripts into filler/speech/command |
| `utils.py` | Text normalization, word matching, helper utilities |

### ğŸ”¹ 2. Updated Voice Agent
Located inside the `agent/` directory:

| File | Description |
|------|-------------|
| `entrypoint.py` | Agent setup, STT/LLM/TTS initialization, hook installation |
| `session_manager.py` | Turn management, event handling, interruption handling |
| `state.py` | Tracks agent speaking state |
| `config.py` | Reads `.env` and provides runtime config |

### ğŸ”¹ 3. Updated Model Stack

The system now uses:

- **Deepgram Nova-3** â†’ STT  
- **OpenAI GPT-4.1-mini** â†’ LLM  
- **Cartesia Sonic-2** â†’ TTS  


## ğŸ—‚ Project Structure

Below is the complete directory layout:
```bash
.
â”œâ”€â”€ agent/
â”‚   â”œâ”€â”€ config.py
â”‚   â”œâ”€â”€ entrypoint.py
â”‚   â”œâ”€â”€ session_manager.py
â”‚   â””â”€â”€ state.py
â”‚
â”œâ”€â”€ interrupt_handler/
â”‚   â”œâ”€â”€ constants.py
â”‚   â”œâ”€â”€ middleware.py
â”‚   â””â”€â”€ utils.py
â”‚
â”œâ”€â”€ .env
â”œâ”€â”€ .env.example
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

## ğŸ§ª Steps to Test

### 1ï¸âƒ£ Clone the Repository
```bash
git clone https://github.com/<your-username>/livekit-interrupt-handler
cd livekit-interrupt-handler
```

### 2ï¸âƒ£ Install Requirements & Prepare Environment

Install Python dependencies:
```bash
pip install -r requirements.txt
```

### Create your environment file:
```bash
cp .env.example .env
```

### Fill in your API keys inside .env :

```bash
# LiveKit Cloud Credentials :

LIVEKIT_URL=
LIVEKIT_API_KEY=
LIVEKIT_API_SECRET=

# Deepgram (Speech-to-Text) : 

DEEPGRAM_API_KEY=

# OpenAI (LLM for GPT-4.1-mini) : 

OPENAI_API_KEY=

# Cartesia (Text-to-Speech) :

CARTESIA_API_KEY=
```