---
"livekit-agents": patch
"livekit-plugins-openai": patch
---

feat: enhance openai LLM metrics to include cached prompt tokens (#1998)
