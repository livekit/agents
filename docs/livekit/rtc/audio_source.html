<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1">
<meta name="generator" content="pdoc3 0.11.6">
<title>livekit.rtc.audio_source API documentation</title>
<meta name="description" content="">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/13.0.0/sanitize.min.css" integrity="sha512-y1dtMcuvtTMJc1yPgEqF0ZjQbhnc/bFhyvIyVNb9Zk5mIGtqVaAB1Ttl28su8AvFMOY0EwRbAe+HCLqj6W7/KA==" crossorigin>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/13.0.0/typography.min.css" integrity="sha512-Y1DYSb995BAfxobCkKepB1BqJJTPrOp3zPL74AWFugHHmmdcvO+C48WLrUOlhGMc0QG7AE3f7gmvvcrmX2fDoA==" crossorigin>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/default.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:1.5em;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:2em 0 .50em 0}h3{font-size:1.4em;margin:1.6em 0 .7em 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .2s ease-in-out}a:visited{color:#503}a:hover{color:#b62}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900;font-weight:bold}pre code{font-size:.8em;line-height:1.4em;padding:1em;display:block}code{background:#f3f3f3;font-family:"DejaVu Sans Mono",monospace;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source > summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible;min-width:max-content}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em 1em;margin:1em 0}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul ul{padding-left:1em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js" integrity="sha512-D9gUyxqja7hBtkWpPWGt9wfbfaMGVt9gnyCvYa+jojwwPHLCzUm5i8rpk7vD7wNee9bA35eYIjobYPaQuKS1MQ==" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => {
hljs.configure({languages: ['bash', 'css', 'diff', 'graphql', 'ini', 'javascript', 'json', 'plaintext', 'python', 'python-repl', 'rust', 'shell', 'sql', 'typescript', 'xml', 'yaml']});
hljs.highlightAll();
/* Collapse source docstrings */
setTimeout(() => {
[...document.querySelectorAll('.hljs.language-python > .hljs-string')]
.filter(el => el.innerHTML.length > 200 && ['"""', "'''"].includes(el.innerHTML.substring(0, 3)))
.forEach(el => {
let d = document.createElement('details');
d.classList.add('hljs-string');
d.innerHTML = '<summary>"""</summary>' + el.innerHTML.substring(3);
el.replaceWith(d);
});
}, 100);
})</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>livekit.rtc.audio_source</code></h1>
</header>
<section id="section-intro">
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="livekit.rtc.audio_source.AudioSource"><code class="flex name class">
<span>class <span class="ident">AudioSource</span></span>
<span>(</span><span>sample_rate: int,<br>num_channels: int,<br>queue_size_ms: int = 1000,<br>loop: asyncio.AbstractEventLoop | None = None)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class AudioSource:
    &#34;&#34;&#34;
    Represents a real-time audio source with an internal audio queue.

    The `AudioSource` class allows you to push audio frames into a real-time audio
    source, managing an internal queue of audio data up to a maximum duration defined
    by `queue_size_ms`. It supports asynchronous operations to capture audio frames
    and to wait for the playback of all queued audio data.
    &#34;&#34;&#34;

    def __init__(
        self,
        sample_rate: int,
        num_channels: int,
        queue_size_ms: int = 1000,
        loop: asyncio.AbstractEventLoop | None = None,
    ) -&gt; None:
        &#34;&#34;&#34;
        Initializes a new instance of the audio source.

        Args:
            sample_rate (int): The sample rate of the audio source in Hz.
            num_channels (int): The number of audio channels.
            queue_size_ms (int, optional): The buffer size of the audio queue in milliseconds.
                Defaults to 1000 ms.
            loop (asyncio.AbstractEventLoop, optional): The event loop to use. Defaults to
                `asyncio.get_event_loop()`.
        &#34;&#34;&#34;
        self._sample_rate = sample_rate
        self._num_channels = num_channels
        self._loop = loop or asyncio.get_event_loop()

        req = proto_ffi.FfiRequest()
        req.new_audio_source.type = proto_audio_frame.AudioSourceType.AUDIO_SOURCE_NATIVE
        req.new_audio_source.sample_rate = sample_rate
        req.new_audio_source.num_channels = num_channels
        req.new_audio_source.queue_size_ms = queue_size_ms

        resp = FfiClient.instance.request(req)
        self._info = resp.new_audio_source.source
        self._ffi_handle = FfiHandle(self._info.handle.id)

        self._last_capture = 0.0
        self._q_size = 0.0
        self._join_handle: asyncio.TimerHandle | None = None
        self._join_fut: asyncio.Future[None] | None = None

    @property
    def sample_rate(self) -&gt; int:
        &#34;&#34;&#34;The sample rate of the audio source in Hz.&#34;&#34;&#34;
        return self._sample_rate

    @property
    def num_channels(self) -&gt; int:
        &#34;&#34;&#34;The number of audio channels.&#34;&#34;&#34;
        return self._num_channels

    @property
    def queued_duration(self) -&gt; float:
        &#34;&#34;&#34;The current duration (in seconds) of audio data queued for playback.&#34;&#34;&#34;
        return max(self._q_size - time.monotonic() + self._last_capture, 0.0)

    def clear_queue(self) -&gt; None:
        &#34;&#34;&#34;
        Clears the internal audio queue, discarding all buffered audio data.

        This method immediately removes all audio data currently queued for playback,
        effectively resetting the audio source&#39;s buffer. Any audio frames that have been
        captured but not yet played will be discarded. This is useful in scenarios where
        you need to stop playback abruptly or prevent outdated audio data from being played.
        &#34;&#34;&#34;
        req = proto_ffi.FfiRequest()
        req.clear_audio_buffer.source_handle = self._ffi_handle.handle
        _ = FfiClient.instance.request(req)
        self._release_waiter()

    async def capture_frame(self, frame: AudioFrame) -&gt; None:
        &#34;&#34;&#34;
        Captures an `AudioFrame` and queues it for playback.

        This method is used to push new audio data into the audio source. The audio data
        will be processed and queued. If the size of the audio frame exceeds the internal
        queue size, the method will wait until there is enough space in the queue to
        accommodate the frame. The method returns only when all of the data in the buffer
        has been pushed.

        Args:
            frame (AudioFrame): The audio frame to capture and queue.

        Raises:
            Exception: If there is an error during frame capture.
        &#34;&#34;&#34;

        if frame.samples_per_channel == 0 or self._ffi_handle.disposed:
            return

        now = time.monotonic()
        elapsed = 0.0 if self._last_capture == 0.0 else now - self._last_capture
        self._q_size += frame.samples_per_channel / self.sample_rate - elapsed
        self._last_capture = now

        if self._join_handle:
            self._join_handle.cancel()

        if self._join_fut is None:
            self._join_fut = self._loop.create_future()

        self._join_handle = self._loop.call_later(self._q_size, self._release_waiter)

        req = proto_ffi.FfiRequest()
        req.capture_audio_frame.source_handle = self._ffi_handle.handle
        req.capture_audio_frame.buffer.CopyFrom(frame._proto_info())

        queue = FfiClient.instance.queue.subscribe(loop=self._loop)
        try:
            resp = FfiClient.instance.request(req)
            cb: proto_ffi.FfiEvent = await queue.wait_for(
                lambda e: e.capture_audio_frame.async_id == resp.capture_audio_frame.async_id
            )
        finally:
            FfiClient.instance.queue.unsubscribe(queue)

        if cb.capture_audio_frame.error:
            raise Exception(cb.capture_audio_frame.error)

    async def wait_for_playout(self) -&gt; None:
        &#34;&#34;&#34;
        Waits for the audio source to finish playing out all audio data.

        This method ensures that all queued audio data has been played out before returning.
        It can be used to synchronize events after audio playback or to ensure that the
        audio queue is empty.
        &#34;&#34;&#34;

        if self._join_fut is None:
            return

        await asyncio.shield(self._join_fut)

    def _release_waiter(self) -&gt; None:
        if self._join_fut is None:
            return  # could be None when clear_queue is called

        if not self._join_fut.done():
            self._join_fut.set_result(None)

        self._last_capture = 0.0
        self._q_size = 0.0
        self._join_fut = None

    async def aclose(self) -&gt; None:
        &#34;&#34;&#34;Close the audio source

        This method cleans up resources associated with the audio source.
        &#34;&#34;&#34;
        self._ffi_handle.dispose()</code></pre>
</details>
<div class="desc"><p>Represents a real-time audio source with an internal audio queue.</p>
<p>The <code><a title="livekit.rtc.audio_source.AudioSource" href="#livekit.rtc.audio_source.AudioSource">AudioSource</a></code> class allows you to push audio frames into a real-time audio
source, managing an internal queue of audio data up to a maximum duration defined
by <code>queue_size_ms</code>. It supports asynchronous operations to capture audio frames
and to wait for the playback of all queued audio data.</p>
<p>Initializes a new instance of the audio source.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>sample_rate</code></strong> :&ensp;<code>int</code></dt>
<dd>The sample rate of the audio source in Hz.</dd>
<dt><strong><code>num_channels</code></strong> :&ensp;<code>int</code></dt>
<dd>The number of audio channels.</dd>
<dt><strong><code>queue_size_ms</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>The buffer size of the audio queue in milliseconds.
Defaults to 1000 ms.</dd>
<dt><strong><code>loop</code></strong> :&ensp;<code>asyncio.AbstractEventLoop</code>, optional</dt>
<dd>The event loop to use. Defaults to
<code>asyncio.get_event_loop()</code>.</dd>
</dl></div>
<h3>Instance variables</h3>
<dl>
<dt id="livekit.rtc.audio_source.AudioSource.num_channels"><code class="name">prop <span class="ident">num_channels</span> : int</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def num_channels(self) -&gt; int:
    &#34;&#34;&#34;The number of audio channels.&#34;&#34;&#34;
    return self._num_channels</code></pre>
</details>
<div class="desc"><p>The number of audio channels.</p></div>
</dd>
<dt id="livekit.rtc.audio_source.AudioSource.queued_duration"><code class="name">prop <span class="ident">queued_duration</span> : float</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def queued_duration(self) -&gt; float:
    &#34;&#34;&#34;The current duration (in seconds) of audio data queued for playback.&#34;&#34;&#34;
    return max(self._q_size - time.monotonic() + self._last_capture, 0.0)</code></pre>
</details>
<div class="desc"><p>The current duration (in seconds) of audio data queued for playback.</p></div>
</dd>
<dt id="livekit.rtc.audio_source.AudioSource.sample_rate"><code class="name">prop <span class="ident">sample_rate</span> : int</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def sample_rate(self) -&gt; int:
    &#34;&#34;&#34;The sample rate of the audio source in Hz.&#34;&#34;&#34;
    return self._sample_rate</code></pre>
</details>
<div class="desc"><p>The sample rate of the audio source in Hz.</p></div>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="livekit.rtc.audio_source.AudioSource.aclose"><code class="name flex">
<span>async def <span class="ident">aclose</span></span>(<span>self) ‑> None</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">async def aclose(self) -&gt; None:
    &#34;&#34;&#34;Close the audio source

    This method cleans up resources associated with the audio source.
    &#34;&#34;&#34;
    self._ffi_handle.dispose()</code></pre>
</details>
<div class="desc"><p>Close the audio source</p>
<p>This method cleans up resources associated with the audio source.</p></div>
</dd>
<dt id="livekit.rtc.audio_source.AudioSource.capture_frame"><code class="name flex">
<span>async def <span class="ident">capture_frame</span></span>(<span>self, frame: AudioFrame) ‑> None</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">async def capture_frame(self, frame: AudioFrame) -&gt; None:
    &#34;&#34;&#34;
    Captures an `AudioFrame` and queues it for playback.

    This method is used to push new audio data into the audio source. The audio data
    will be processed and queued. If the size of the audio frame exceeds the internal
    queue size, the method will wait until there is enough space in the queue to
    accommodate the frame. The method returns only when all of the data in the buffer
    has been pushed.

    Args:
        frame (AudioFrame): The audio frame to capture and queue.

    Raises:
        Exception: If there is an error during frame capture.
    &#34;&#34;&#34;

    if frame.samples_per_channel == 0 or self._ffi_handle.disposed:
        return

    now = time.monotonic()
    elapsed = 0.0 if self._last_capture == 0.0 else now - self._last_capture
    self._q_size += frame.samples_per_channel / self.sample_rate - elapsed
    self._last_capture = now

    if self._join_handle:
        self._join_handle.cancel()

    if self._join_fut is None:
        self._join_fut = self._loop.create_future()

    self._join_handle = self._loop.call_later(self._q_size, self._release_waiter)

    req = proto_ffi.FfiRequest()
    req.capture_audio_frame.source_handle = self._ffi_handle.handle
    req.capture_audio_frame.buffer.CopyFrom(frame._proto_info())

    queue = FfiClient.instance.queue.subscribe(loop=self._loop)
    try:
        resp = FfiClient.instance.request(req)
        cb: proto_ffi.FfiEvent = await queue.wait_for(
            lambda e: e.capture_audio_frame.async_id == resp.capture_audio_frame.async_id
        )
    finally:
        FfiClient.instance.queue.unsubscribe(queue)

    if cb.capture_audio_frame.error:
        raise Exception(cb.capture_audio_frame.error)</code></pre>
</details>
<div class="desc"><p>Captures an <code>AudioFrame</code> and queues it for playback.</p>
<p>This method is used to push new audio data into the audio source. The audio data
will be processed and queued. If the size of the audio frame exceeds the internal
queue size, the method will wait until there is enough space in the queue to
accommodate the frame. The method returns only when all of the data in the buffer
has been pushed.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>frame</code></strong> :&ensp;<code>AudioFrame</code></dt>
<dd>The audio frame to capture and queue.</dd>
</dl>
<h2 id="raises">Raises</h2>
<dl>
<dt><code>Exception</code></dt>
<dd>If there is an error during frame capture.</dd>
</dl></div>
</dd>
<dt id="livekit.rtc.audio_source.AudioSource.clear_queue"><code class="name flex">
<span>def <span class="ident">clear_queue</span></span>(<span>self) ‑> None</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def clear_queue(self) -&gt; None:
    &#34;&#34;&#34;
    Clears the internal audio queue, discarding all buffered audio data.

    This method immediately removes all audio data currently queued for playback,
    effectively resetting the audio source&#39;s buffer. Any audio frames that have been
    captured but not yet played will be discarded. This is useful in scenarios where
    you need to stop playback abruptly or prevent outdated audio data from being played.
    &#34;&#34;&#34;
    req = proto_ffi.FfiRequest()
    req.clear_audio_buffer.source_handle = self._ffi_handle.handle
    _ = FfiClient.instance.request(req)
    self._release_waiter()</code></pre>
</details>
<div class="desc"><p>Clears the internal audio queue, discarding all buffered audio data.</p>
<p>This method immediately removes all audio data currently queued for playback,
effectively resetting the audio source's buffer. Any audio frames that have been
captured but not yet played will be discarded. This is useful in scenarios where
you need to stop playback abruptly or prevent outdated audio data from being played.</p></div>
</dd>
<dt id="livekit.rtc.audio_source.AudioSource.wait_for_playout"><code class="name flex">
<span>async def <span class="ident">wait_for_playout</span></span>(<span>self) ‑> None</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">async def wait_for_playout(self) -&gt; None:
    &#34;&#34;&#34;
    Waits for the audio source to finish playing out all audio data.

    This method ensures that all queued audio data has been played out before returning.
    It can be used to synchronize events after audio playback or to ensure that the
    audio queue is empty.
    &#34;&#34;&#34;

    if self._join_fut is None:
        return

    await asyncio.shield(self._join_fut)</code></pre>
</details>
<div class="desc"><p>Waits for the audio source to finish playing out all audio data.</p>
<p>This method ensures that all queued audio data has been played out before returning.
It can be used to synchronize events after audio playback or to ensure that the
audio queue is empty.</p></div>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="livekit.rtc" href="index.html">livekit.rtc</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="livekit.rtc.audio_source.AudioSource" href="#livekit.rtc.audio_source.AudioSource">AudioSource</a></code></h4>
<ul class="two-column">
<li><code><a title="livekit.rtc.audio_source.AudioSource.aclose" href="#livekit.rtc.audio_source.AudioSource.aclose">aclose</a></code></li>
<li><code><a title="livekit.rtc.audio_source.AudioSource.capture_frame" href="#livekit.rtc.audio_source.AudioSource.capture_frame">capture_frame</a></code></li>
<li><code><a title="livekit.rtc.audio_source.AudioSource.clear_queue" href="#livekit.rtc.audio_source.AudioSource.clear_queue">clear_queue</a></code></li>
<li><code><a title="livekit.rtc.audio_source.AudioSource.num_channels" href="#livekit.rtc.audio_source.AudioSource.num_channels">num_channels</a></code></li>
<li><code><a title="livekit.rtc.audio_source.AudioSource.queued_duration" href="#livekit.rtc.audio_source.AudioSource.queued_duration">queued_duration</a></code></li>
<li><code><a title="livekit.rtc.audio_source.AudioSource.sample_rate" href="#livekit.rtc.audio_source.AudioSource.sample_rate">sample_rate</a></code></li>
<li><code><a title="livekit.rtc.audio_source.AudioSource.wait_for_playout" href="#livekit.rtc.audio_source.AudioSource.wait_for_playout">wait_for_playout</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.11.6</a>.</p>
</footer>
</body>
</html>
