<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1">
<meta name="generator" content="pdoc3 0.11.6">
<title>livekit.rtc.audio_mixer API documentation</title>
<meta name="description" content="">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/13.0.0/sanitize.min.css" integrity="sha512-y1dtMcuvtTMJc1yPgEqF0ZjQbhnc/bFhyvIyVNb9Zk5mIGtqVaAB1Ttl28su8AvFMOY0EwRbAe+HCLqj6W7/KA==" crossorigin>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/13.0.0/typography.min.css" integrity="sha512-Y1DYSb995BAfxobCkKepB1BqJJTPrOp3zPL74AWFugHHmmdcvO+C48WLrUOlhGMc0QG7AE3f7gmvvcrmX2fDoA==" crossorigin>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/default.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:1.5em;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:2em 0 .50em 0}h3{font-size:1.4em;margin:1.6em 0 .7em 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .2s ease-in-out}a:visited{color:#503}a:hover{color:#b62}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900;font-weight:bold}pre code{font-size:.8em;line-height:1.4em;padding:1em;display:block}code{background:#f3f3f3;font-family:"DejaVu Sans Mono",monospace;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source > summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible;min-width:max-content}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em 1em;margin:1em 0}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul ul{padding-left:1em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js" integrity="sha512-D9gUyxqja7hBtkWpPWGt9wfbfaMGVt9gnyCvYa+jojwwPHLCzUm5i8rpk7vD7wNee9bA35eYIjobYPaQuKS1MQ==" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => {
hljs.configure({languages: ['bash', 'css', 'diff', 'graphql', 'ini', 'javascript', 'json', 'plaintext', 'python', 'python-repl', 'rust', 'shell', 'sql', 'typescript', 'xml', 'yaml']});
hljs.highlightAll();
/* Collapse source docstrings */
setTimeout(() => {
[...document.querySelectorAll('.hljs.language-python > .hljs-string')]
.filter(el => el.innerHTML.length > 200 && ['"""', "'''"].includes(el.innerHTML.substring(0, 3)))
.forEach(el => {
let d = document.createElement('details');
d.classList.add('hljs-string');
d.innerHTML = '<summary>"""</summary>' + el.innerHTML.substring(3);
el.replaceWith(d);
});
}, 100);
})</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>livekit.rtc.audio_mixer</code></h1>
</header>
<section id="section-intro">
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="livekit.rtc.audio_mixer.AudioMixer"><code class="flex name class">
<span>class <span class="ident">AudioMixer</span></span>
<span>(</span><span>sample_rate: int,<br>num_channels: int,<br>*,<br>blocksize: int = 0,<br>stream_timeout_ms: int = 100,<br>capacity: int = 100)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class AudioMixer:
    def __init__(
        self,
        sample_rate: int,
        num_channels: int,
        *,
        blocksize: int = 0,
        stream_timeout_ms: int = 100,
        capacity: int = 100,
    ) -&gt; None:
        &#34;&#34;&#34;
        Initialize the AudioMixer.

        The mixer accepts multiple async audio streams and mixes them into a single output stream.
        Each output frame is generated with a fixed chunk size determined by the blocksize (in samples).
        If blocksize is not provided (or 0), it defaults to 100ms.

        Each input stream is processed in parallel, accumulating audio data until at least one chunk
        of samples is available. If an input stream does not provide data within the specified timeout,
        a warning is logged. The mixer can be closed immediately
        (dropping unconsumed frames) or allowed to flush remaining data using end_input().

        Args:
            sample_rate (int): The audio sample rate in Hz.
            num_channels (int): The number of audio channels.
            blocksize (int, optional): The size of the audio block (in samples) for mixing. If not provided,
                defaults to sample_rate // 10.
            stream_timeout_ms (int, optional): The maximum wait time in milliseconds for each stream to provide
                audio data before timing out. Defaults to 100 ms.
            capacity (int, optional): The maximum number of mixed frames to store in the output queue.
                Defaults to 100.
        &#34;&#34;&#34;
        self._streams: set[_Stream] = set()
        self._buffers: dict[_Stream, np.ndarray] = {}
        self._sample_rate: int = sample_rate
        self._num_channels: int = num_channels
        self._chunk_size: int = blocksize if blocksize &gt; 0 else int(sample_rate // 10)
        self._stream_timeout_ms: int = stream_timeout_ms
        self._queue: asyncio.Queue[Optional[AudioFrame]] = asyncio.Queue(maxsize=capacity)
        # _ending signals that no new streams will be added,
        # but we continue processing until all streams are exhausted.
        self._ending: bool = False
        self._mixer_task: asyncio.Task = asyncio.create_task(self._mixer())

    def add_stream(self, stream: AsyncIterator[AudioFrame]) -&gt; None:
        &#34;&#34;&#34;
        Add an audio stream to the mixer.

        The stream is added to the internal set of streams and an empty buffer is initialized for it,
        if not already present.

        Args:
            stream (AsyncIterator[AudioFrame]): An async iterator that produces AudioFrame objects.
        &#34;&#34;&#34;
        if self._ending:
            raise RuntimeError(&#34;Cannot add stream after mixer has been closed&#34;)

        self._streams.add(stream)
        if stream not in self._buffers:
            self._buffers[stream] = np.empty((0, self._num_channels), dtype=np.int16)

    def remove_stream(self, stream: AsyncIterator[AudioFrame]) -&gt; None:
        &#34;&#34;&#34;
        Remove an audio stream from the mixer.

        This method removes the specified stream and its associated buffer from the mixer.

        Args:
            stream (AsyncIterator[AudioFrame]): The audio stream to remove.
        &#34;&#34;&#34;
        self._streams.discard(stream)
        self._buffers.pop(stream, None)

    def __aiter__(self) -&gt; &#34;AudioMixer&#34;:
        return self

    async def __anext__(self) -&gt; AudioFrame:
        item = await self._queue.get()
        if item is None:
            raise StopAsyncIteration
        return item

    async def aclose(self) -&gt; None:
        &#34;&#34;&#34;
        Immediately stop mixing and close the mixer.

        This cancels the mixing task, and any unconsumed output in the queue may be dropped.
        &#34;&#34;&#34;
        self._ending = True
        self._mixer_task.cancel()
        with contextlib.suppress(asyncio.CancelledError):
            await self._mixer_task

    def end_input(self) -&gt; None:
        &#34;&#34;&#34;
        Signal that no more streams will be added.

        This method marks the mixer as closed so that it flushes any remaining buffered output before ending.
        Note that existing streams will still be processed until exhausted.
        &#34;&#34;&#34;
        self._ending = True

    async def _mixer(self) -&gt; None:
        while True:
            # If we&#39;re in ending mode and there are no more streams, exit.
            if self._ending and not self._streams:
                break

            if not self._streams:
                await asyncio.sleep(0.01)
                continue

            tasks = [
                self._get_contribution(
                    stream,
                    self._buffers.get(stream, np.empty((0, self._num_channels), dtype=np.int16)),
                )
                for stream in list(self._streams)
            ]
            results = await asyncio.gather(*tasks, return_exceptions=True)
            contributions = []
            any_data = False
            removals = []
            for contrib in results:
                if not isinstance(contrib, _Contribution):
                    continue

                contributions.append(contrib.data.astype(np.float32))
                self._buffers[contrib.stream] = contrib.buffer
                if contrib.had_data:
                    any_data = True
                if contrib.exhausted and contrib.buffer.shape[0] == 0:
                    removals.append(contrib.stream)

            for stream in removals:
                self.remove_stream(stream)

            if not any_data:
                await asyncio.sleep(0.001)
                continue

            mixed = np.sum(np.stack(contributions, axis=0), axis=0)
            mixed = np.clip(mixed, -32768, 32767).astype(np.int16)
            frame = AudioFrame(
                mixed.tobytes(), self._sample_rate, self._num_channels, self._chunk_size
            )
            await self._queue.put(frame)

        await self._queue.put(None)

    async def _get_contribution(
        self, stream: AsyncIterator[AudioFrame], buf: np.ndarray
    ) -&gt; _Contribution:
        had_data = buf.shape[0] &gt; 0
        exhausted = False
        while buf.shape[0] &lt; self._chunk_size and not exhausted:
            try:
                frame = await asyncio.wait_for(
                    stream.__anext__(), timeout=self._stream_timeout_ms / 1000
                )
            except asyncio.TimeoutError:
                logger.warning(f&#34;AudioMixer: stream {stream} timeout, ignoring&#34;)
                break
            except StopAsyncIteration:
                exhausted = True
                break
            new_data = np.frombuffer(frame.data.tobytes(), dtype=np.int16).reshape(
                -1, self._num_channels
            )
            buf = np.concatenate((buf, new_data), axis=0) if buf.size else new_data
            had_data = True
        if buf.shape[0] &gt;= self._chunk_size:
            contrib, buf = buf[: self._chunk_size], buf[self._chunk_size :]
        else:
            pad = np.zeros((self._chunk_size - buf.shape[0], self._num_channels), dtype=np.int16)
            contrib, buf = (
                np.concatenate((buf, pad), axis=0),
                np.empty((0, self._num_channels), dtype=np.int16),
            )
        return _Contribution(stream, contrib, buf, had_data, exhausted)</code></pre>
</details>
<div class="desc"><p>Initialize the AudioMixer.</p>
<p>The mixer accepts multiple async audio streams and mixes them into a single output stream.
Each output frame is generated with a fixed chunk size determined by the blocksize (in samples).
If blocksize is not provided (or 0), it defaults to 100ms.</p>
<p>Each input stream is processed in parallel, accumulating audio data until at least one chunk
of samples is available. If an input stream does not provide data within the specified timeout,
a warning is logged. The mixer can be closed immediately
(dropping unconsumed frames) or allowed to flush remaining data using end_input().</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>sample_rate</code></strong> :&ensp;<code>int</code></dt>
<dd>The audio sample rate in Hz.</dd>
<dt><strong><code>num_channels</code></strong> :&ensp;<code>int</code></dt>
<dd>The number of audio channels.</dd>
<dt><strong><code>blocksize</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>The size of the audio block (in samples) for mixing. If not provided,
defaults to sample_rate // 10.</dd>
<dt><strong><code>stream_timeout_ms</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>The maximum wait time in milliseconds for each stream to provide
audio data before timing out. Defaults to 100 ms.</dd>
<dt><strong><code>capacity</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>The maximum number of mixed frames to store in the output queue.
Defaults to 100.</dd>
</dl></div>
<h3>Methods</h3>
<dl>
<dt id="livekit.rtc.audio_mixer.AudioMixer.aclose"><code class="name flex">
<span>async def <span class="ident">aclose</span></span>(<span>self) ‑> None</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">async def aclose(self) -&gt; None:
    &#34;&#34;&#34;
    Immediately stop mixing and close the mixer.

    This cancels the mixing task, and any unconsumed output in the queue may be dropped.
    &#34;&#34;&#34;
    self._ending = True
    self._mixer_task.cancel()
    with contextlib.suppress(asyncio.CancelledError):
        await self._mixer_task</code></pre>
</details>
<div class="desc"><p>Immediately stop mixing and close the mixer.</p>
<p>This cancels the mixing task, and any unconsumed output in the queue may be dropped.</p></div>
</dd>
<dt id="livekit.rtc.audio_mixer.AudioMixer.add_stream"><code class="name flex">
<span>def <span class="ident">add_stream</span></span>(<span>self,<br>stream: AsyncIterator[<a title="livekit.rtc.audio_frame.AudioFrame" href="audio_frame.html#livekit.rtc.audio_frame.AudioFrame">AudioFrame</a>]) ‑> None</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def add_stream(self, stream: AsyncIterator[AudioFrame]) -&gt; None:
    &#34;&#34;&#34;
    Add an audio stream to the mixer.

    The stream is added to the internal set of streams and an empty buffer is initialized for it,
    if not already present.

    Args:
        stream (AsyncIterator[AudioFrame]): An async iterator that produces AudioFrame objects.
    &#34;&#34;&#34;
    if self._ending:
        raise RuntimeError(&#34;Cannot add stream after mixer has been closed&#34;)

    self._streams.add(stream)
    if stream not in self._buffers:
        self._buffers[stream] = np.empty((0, self._num_channels), dtype=np.int16)</code></pre>
</details>
<div class="desc"><p>Add an audio stream to the mixer.</p>
<p>The stream is added to the internal set of streams and an empty buffer is initialized for it,
if not already present.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>stream</code></strong> :&ensp;<code>AsyncIterator[AudioFrame]</code></dt>
<dd>An async iterator that produces AudioFrame objects.</dd>
</dl></div>
</dd>
<dt id="livekit.rtc.audio_mixer.AudioMixer.end_input"><code class="name flex">
<span>def <span class="ident">end_input</span></span>(<span>self) ‑> None</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def end_input(self) -&gt; None:
    &#34;&#34;&#34;
    Signal that no more streams will be added.

    This method marks the mixer as closed so that it flushes any remaining buffered output before ending.
    Note that existing streams will still be processed until exhausted.
    &#34;&#34;&#34;
    self._ending = True</code></pre>
</details>
<div class="desc"><p>Signal that no more streams will be added.</p>
<p>This method marks the mixer as closed so that it flushes any remaining buffered output before ending.
Note that existing streams will still be processed until exhausted.</p></div>
</dd>
<dt id="livekit.rtc.audio_mixer.AudioMixer.remove_stream"><code class="name flex">
<span>def <span class="ident">remove_stream</span></span>(<span>self,<br>stream: AsyncIterator[<a title="livekit.rtc.audio_frame.AudioFrame" href="audio_frame.html#livekit.rtc.audio_frame.AudioFrame">AudioFrame</a>]) ‑> None</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def remove_stream(self, stream: AsyncIterator[AudioFrame]) -&gt; None:
    &#34;&#34;&#34;
    Remove an audio stream from the mixer.

    This method removes the specified stream and its associated buffer from the mixer.

    Args:
        stream (AsyncIterator[AudioFrame]): The audio stream to remove.
    &#34;&#34;&#34;
    self._streams.discard(stream)
    self._buffers.pop(stream, None)</code></pre>
</details>
<div class="desc"><p>Remove an audio stream from the mixer.</p>
<p>This method removes the specified stream and its associated buffer from the mixer.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>stream</code></strong> :&ensp;<code>AsyncIterator[AudioFrame]</code></dt>
<dd>The audio stream to remove.</dd>
</dl></div>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="livekit.rtc" href="index.html">livekit.rtc</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="livekit.rtc.audio_mixer.AudioMixer" href="#livekit.rtc.audio_mixer.AudioMixer">AudioMixer</a></code></h4>
<ul class="">
<li><code><a title="livekit.rtc.audio_mixer.AudioMixer.aclose" href="#livekit.rtc.audio_mixer.AudioMixer.aclose">aclose</a></code></li>
<li><code><a title="livekit.rtc.audio_mixer.AudioMixer.add_stream" href="#livekit.rtc.audio_mixer.AudioMixer.add_stream">add_stream</a></code></li>
<li><code><a title="livekit.rtc.audio_mixer.AudioMixer.end_input" href="#livekit.rtc.audio_mixer.AudioMixer.end_input">end_input</a></code></li>
<li><code><a title="livekit.rtc.audio_mixer.AudioMixer.remove_stream" href="#livekit.rtc.audio_mixer.AudioMixer.remove_stream">remove_stream</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.11.6</a>.</p>
</footer>
</body>
</html>
