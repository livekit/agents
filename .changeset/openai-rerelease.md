---
"livekit-plugins-openai": patch
---

feat: add max_tokens option to LLM and LLMStream classes
