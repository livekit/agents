# SalesCode.ai Assessment: LiveKit - A powerful framework for building realtime voice AI agents

This repository contains my implementation of a **multilingual, filler-aware, interruption-safe voice assistant** built using the **LiveKit Agents** framework.  
The goal of this work was to create a more natural and intelligent voice interaction system that understands the difference between *filler noise* and *real user interruptions* ‚Äî something real conversational AI systems must handle correctly.

I reorganized and renamed the modules into a clean package called **`chat_processor`** to separate custom logic from the default example structure.

---

## Features & Capabilities

### ‚úî Filler Words Are Ignored While Agent Speaks
The agent does **not** interrupt itself when the user says:
- `uh`
- `umm`
- `hmm`
- `haan`
- or any other filler word you add dynamically

### ‚úî Filler Words Count as Valid Input When Agent Is Silent
If the agent is not speaking, even ‚Äúumm‚Äù becomes `"user_speech"`.

### ‚úî Real User Interruptions Instantly Stop the Agent
Works for both languages:

**English:**  
`stop`, `wait`, `hold on`, `no`  

**Hindi:**  
`ruko`, `band`, `nahi`

### ‚úî English + Hindi Language Detection  
The model automatically switches word-lists based on STT language tags.

### ‚úî Live Dynamic Updates  
Modify `agent_profile.json` and the agent updates **without restarting**.

### ‚úî Clean Comparison Against Baseline  
Two agents included:
- `main_agent.py` ‚Üí full intelligent behavior  
- `default_agent.py` ‚Üí plain LiveKit behavior (interrupts on everything)

---

## üìÅ Project Structure
```
project-root/
    chat_processor/
        agent_config.py
        intent_detector.py
        memory_manager.py
        settings_loader.py

    main_agent.py
    default_agent.py
    agent_profile.json
```


### **Module Responsibilities**

#### `agent_config.py`
- Loads all environment variables
- Builds a central `Settings` object
- Handles filler words, command words, default language, dynamic config path

#### `intent_detector.py`
Implements the core classification logic:
- `"ignore_filler"`
- `"interrupt_agent"`
- `"user_speech"`

#### `memory_manager.py`
Tracks agent & user speaking states:
- `is_agent_speaking()`
- `is_user_speaking()`

#### `settings_loader.py`
- Loads filler & command words
- Watches JSON file for live updates
- Handles multilingual behavior

#### `main_agent.py`
- Integrates STT ‚Üí VAD ‚Üí LLM ‚Üí TTS
- Uses custom filler-aware interruption logic
- Applies multilingual rules
- Uses `min_interruption_words=2` to avoid false interrupts

#### `default_agent.py`
- No custom logic
- Uses LiveKit‚Äôs default interruption behavior
- Useful for comparison

---

## Intelligent Classification Logic (Summary)

1. **If the agent is not speaking**  
   ‚Üí **Everything counts as user speech**

2. **If the agent is speaking:**
   - Contains interrupt word ‚Üí `"interrupt_agent"`
   - All tokens are fillers ‚Üí `"ignore_filler"`
   - Very short confirmations ‚Üí `"ignore_filler"`
   - Anything else ‚Üí `"interrupt_agent"`

This improves conversation flow and reduces accidental cutoffs.

---

## Installation & Setup

### 1. Clone the repository

```bash
git clone <repo>
cd <project-root>
```

2. Create a virtual environment

```
python -m venv .venv
source .venv/bin/activate      # macOS / Linux
.venv\Scripts\activate         # Windows
```

4. Install dependencies

```
pip install "livekit-agents[openai,silero,deepgram,cartesia,turn-detector]~=1.3"
pip install python-dotenv
```

6. Create a .env file
    ```
    LIVEKIT_URL=your_url
    LIVEKIT_API_KEY=your_key
    LIVEKIT_API_SECRET=your_secret
    OPENAI_API_KEY=sk-xxxx
    LIVEKIT_INFERENCE_USE_DIRECT_OPENAI=1
    DEFAULT_LANGUAGE=en
    FILLER_CONFIDENCE_THRESHOLD=0.6
    FILLER_CONFIG_PATH=./agent_profile.json
    ```

7. Create the dynamic config file
```
agent_profile.json
```

‚ñ∂ Running the Agents

```
python main_agent.py console
```
Run the baseline agent
```
python default_agent.py console
```

# Verified Behaviour During Testing
1. Correctly ignores filler words during TTS
2. Correctly treats fillers as speech when agent is silent
3. Interrupts instantly on real interruption commands
4. Selects correct language profile based on STT
5. Reacts instantly to JSON updates
6. Baseline agent interrupts on all noise (intended behavior)




